= Reporte de optimizaciones
:experimental:
:nofooter:
:source-highlighter: pygments
:sectnums:
:stem: latexmath
:toc:
:xrefstyle: short



[[serial_optimizations]]
== Optimizaciones seriales

[%autowidth.stretch,options="header"]
|===
|Iter. |Etiqueta |Duración (s) |_Speedup_ |Descripción corta
|0 |Serial0 | |1.00 |Versión serial inicial (Tarea01)
|1 |Serial1 | |1.00 |Intercambio de matrices por punteros
|2 |Serial2 | |1.00 |Copia de matrices con memcpy
|===


[[serial_iter00]]
=== Versión serial original (Tarea01)

En la versión serial original del programa de simulación de transferencia de calor (Tarea01), había varios aspectos que afectaban la eficiencia y otros que, por su naturaleza, no requerían mayor optimización. A continuación, se describen ambos casos:

=== Aspectos no eficientes

1. *Uso de una matriz temporal*:  
   En la simulación de transferencia de calor, se utilizaba una matriz temporal para calcular los nuevos valores de temperatura en cada iteración. Aunque es una implementación correcta, puede no ser eficiente en cuanto al uso de memoria, ya que se duplican los datos en matrices grandes. Además, esto conlleva la necesidad de copiar los valores de vuelta a la matriz original, lo cual agrega operaciones adicionales.

2. *Actualización secuencial de la matriz*:  
   La actualización de la matriz en cada iteración se realiza de manera secuencial, lo cual es inherentemente ineficiente en sistemas con múltiples núcleos. Cada celda de la matriz se calcula una tras otra, sin aprovechar las capacidades de procesamiento paralelo.

3. *Verificación del punto de equilibrio en cada celda*:  
   La condición de equilibrio se evalúa celda por celda en cada iteración. Esto implica una gran cantidad de cálculos y comparaciones que podrían optimizarse si se implementaran técnicas más eficientes de verificación, como una comparación de matrices por bloques en lugar de por celdas individuales.

4. *Acceso repetitivo a datos de bordes*:  
   Aunque la simulación sólo actualiza las celdas internas, las celdas de los bordes se leen repetidamente en cada iteración. Dado que estos bordes no cambian, almacenar y gestionar estos valores de forma separada podría reducir el número de accesos innecesarios a memoria.

=== Aspectos eficientes

1. *Uso de condiciones de frontera estáticas*:  
   Las celdas de los bordes de la matriz se mantienen constantes a lo largo de la simulación. Esto es eficiente, ya que permite evitar cálculos adicionales en dichas celdas, lo cual optimiza el rendimiento en esa parte de la simulación.

2. *Gestión sencilla de memoria*:  
   Aunque el uso de matrices temporales podría optimizarse, la asignación de memoria para las matrices se maneja de manera simple y directa, evitando fugas de memoria y problemas con la administración de recursos, lo cual ya es una ventaja en términos de eficiencia operativa.

=== Razones por las cuales algunos aspectos no ameritaban optimización

- *Complejidad algorítmica*:  
   El algoritmo utilizado en la versión serial es de naturaleza iterativa y, a menos que se modifique el enfoque general (como cambiar a métodos implícitos que requieren la solución de sistemas de ecuaciones), las optimizaciones más allá de paralelizar el proceso no son significativamente efectivas.

- *Simulación correcta*:  
   Aunque el código podría no ser el más rápido, la implementación ya logra simular correctamente el fenómeno físico con los parámetros dados, por lo que no era estrictamente necesario optimizarlo si la simulación no era extremadamente lenta o demandante en términos de tiempo de cómputo.

En resumen, la versión serial tenía aspectos que se podían optimizar, principalmente en cuanto al uso de memoria y la paralelización de la simulación, mientras que otros aspectos, como el método utilizado y la gestión de las condiciones de frontera, ya eran eficientes y no requerían optimizaciones adicionales.


[[serial_iter01]] 
=== Iteración 1: Optimización de Alternancia de Matrices

La primera optimización se centró en mejorar el uso de memoria y eliminar la sobrecarga de copiar la matriz completa al final de cada iteración. La versión original utilizaba una matriz temporal para almacenar los nuevos valores calculados durante cada iteración, lo que requería una copia completa de la matriz al finalizar cada iteración. Para evitar esta duplicación innecesaria de datos, se implementó una técnica de alternancia de matrices, en la que dos matrices (matrix_a y matrix_b) intercambian roles en cada iteración. La matriz actual se usa para calcular los nuevos valores, mientras que la otra almacena el nuevo estado. Este proceso elimina la necesidad de copiar grandes cantidades de datos y optimiza el uso de memoria.

image::screen_shots/pseudo.png[Pseudocódigo]

Resultado:
La optimización redujo la sobrecarga de copiar la matriz completa al final de cada iteración, pero mantuvo la capacidad de comparar el estado anterior con el nuevo en cada ciclo de la simulación. En cuanto al desempeño, esta mejora mostró un impacto positivo en simulaciones de gran tamaño, ya que eliminó una operación costosa sin afectar la precisión de los resultados.

[[serial_iter02]]
=== Iteración 2: Corrección en el uso de memcpy en copy_matrix

En esta iteración, gracias a kcachegrind, se pudo observar el consumo de memoria de la función copymatrix, por lo que la optimización se centró en corregir el uso incorrecto de memcpy en la función copy_matrix. En la versión anterior, se intentaba copiar el contenido de las matrices utilizando memcpy de una sola vez, asumiendo que las matrices estaban almacenadas en bloques contiguos de memoria. Sin embargo, las matrices se implementan como arreglos de punteros (double**), donde cada fila está asignada individualmente. Esta estructura requiere que cada fila se copie por separado.

La mejora consistió en modificar la función copy_matrix para copiar cada fila de la matriz de forma individual, asegurando que los datos se transfieren correctamente fila por fila, sin errores de memoria.

image::screen_shots/cache.png[Consumo de memoria]


Resultado:
Esta corrección asegura que los datos de las matrices se copien de manera correcta y eficiente, respetando la estructura en bloques de memoria no contiguos de las matrices de punteros. No se observó un impacto directo en el tiempo de ejecución, pero esta mejora es esencial para la correcta funcionalidad y estabilidad del programa, especialmente en simulaciones con matrices grandes, evitando errores de segmentación o datos incorrectamente copiados.

[[concurrent_optimizations]]
== Optimizaciones concurrentes

[%autowidth.stretch,options="header"]
|===
|Iter. |Etiqueta |Duración (s) |_Speedup_ |Eficiencia |Descripción corta
|- |SerialI | |1.00 |1.00 |Versión serial final
|1 |Conc0 | | | |Versión concurrente inicial (Tarea02)
|2 | | | | |
|3 | | | | |Versión concurrente final
|===


[[conc_iter00]]
=== Versión concurrente inicial (Tarea02)

En la versión concurrente inicial (Tarea02), se introdujeron múltiples hilos para mejorar el rendimiento de la simulación de transferencia de calor, pero a pesar de esto, hubo algunos aspectos que afectaron la eficiencia y que podrían optimizarse más adelante. También hubo algunos aspectos que fueron eficientes desde el principio y no necesitaron ajustes. A continuación, se detallan estos puntos:

==== Aspectos no eficientes

1. *Sincronización mediante barreras*:  
   La implementación inicial utilizaba una barrera para sincronizar a los hilos después de cada iteración de la simulación. Aunque esto es necesario para evitar condiciones de carrera, las barreras introducen una sobrecarga significativa, ya que todos los hilos deben esperar a que los demás terminen su trabajo antes de proceder a la siguiente iteración. Esto es especialmente ineficiente si algunos hilos terminan antes que otros debido a una distribución desigual de la carga de trabajo.

2. *Distribución de carga desigual*:  
   La asignación de filas a los hilos se realizaba de forma equitativa, dividiendo las filas entre los hilos. Sin embargo, algunas filas pueden requerir más procesamiento que otras, lo que resulta en un desequilibrio en la carga de trabajo entre los hilos. Esto puede provocar que algunos hilos esperen a que otros terminen, reduciendo la eficiencia global.

3. *Acceso repetido a la matriz global*:  
   Aunque cada hilo mantenía una copia local de la matriz, el acceso y actualización de la matriz global seguía ocurriendo en cada iteración. Este acceso concurrente a la matriz global requiere el uso de mutexes, lo que puede generar una ralentización debido a la contención en los bloqueos.

4. *Uso de memoria para matrices locales*:  
   Al tener cada hilo su propia matriz local, la memoria requerida aumentó considerablemente, especialmente cuando se manejaban matrices grandes. Esto puede convertirse en un problema cuando el tamaño de la simulación escala, ya que la duplicación de datos implica un mayor uso de recursos.

==== Aspectos eficientes

1. *Paralelización básica*:  
   La introducción de múltiples hilos en la simulación fue un paso importante hacia la mejora del rendimiento. Al paralelizar las operaciones sobre las celdas de la matriz, el tiempo total de simulación se redujo en comparación con la versión serial. Esta estrategia, en principio, es eficiente, ya que permite aprovechar mejor los recursos de hardware disponibles en sistemas con múltiples núcleos.

2. *Independencia de las celdas internas*:  
   Cada hilo solo actualizaba las celdas internas de su porción asignada de la matriz, lo que minimizaba las interacciones entre hilos. Esta independencia ayudó a reducir la posibilidad de condiciones de carrera, ya que cada hilo operaba en una sección separada de la matriz sin interferir con otras.

3. *Uso de matrices locales*:  
   Aunque el uso de matrices locales incrementó el uso de memoria, esta estrategia también fue eficiente en el sentido de que permitió a los hilos trabajar en paralelo sin conflictos directos sobre los datos. Esto redujo la necesidad de sincronización adicional durante la actualización de las celdas, mejorando el rendimiento en comparación con una única matriz compartida.

4. *Control del punto de equilibrio*:  
   La implementación del control del balance point permitió terminar la simulación una vez que se alcanzaba el equilibrio térmico. Esto evitó la ejecución de iteraciones innecesarias, lo que mejoró la eficiencia del algoritmo al finalizar más rápido cuando se cumplía la condición de parada.

==== Razones por las cuales algunos aspectos no ameritaban optimización

- *Simplificación del uso de mutexes*:  
   Aunque el uso de mutexes introduce cierta sobrecarga, fue necesario para asegurar que las actualizaciones de la matriz global fueran consistentes. Si bien podría haber maneras más eficientes de gestionar la sincronización, el uso de mutexes en este contexto ya garantizaba la correcta actualización de los datos compartidos sin errores.

En resumen, la versión concurrente inicial mejoró significativamente el rendimiento mediante la paralelización, pero la sobrecarga de sincronización y la desigual distribución de carga presentaban oportunidades para optimizaciones adicionales. Algunos aspectos, como el uso del método de diferencias finitas y las matrices locales, ya eran eficientes y no ameritaban una optimización significativa.

[[conc_iter01]]
=== Iteración 1

#Para cada iteración del ciclo de optimización, cree una subsección como esta. Resuma en máximo un párrafo en qué consiste la optimización. Su objetivo es que quien lea este documento entienda claramente qué se intentó mejorar. Provea trocitos de código fuente o pseudocódigo que ayude a entender la optimización potencial. Indique si el intento logró incrementar el desempeño. En caso de no lograrlo, conjeture la causa. Eso ayudaría a ahorrar tiempo a otras personas que tengan la misma inquietud.#


[[optimization_comparison]]
=== Comparación de optimizaciones

(pendiente)


[[concurrency_comparison]]
=== Comparación del grado de concurrencia

(pendiente)